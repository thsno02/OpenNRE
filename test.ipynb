{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "## download assets\n",
    "# bash benchmark/download_wiki20m.sh\n",
    "# bash benchmark/download_wiki80.sh\n",
    "# bash benchmark/download_nyt10m.sh\n",
    "# bash benchmark/download_fewrel.sh\n",
    "# bash benchmark/download_nyt10.sh\n",
    "# bash benchmark/download_semeval.sh\n",
    "# bash pretrain/download_bert.sh\n",
    "# bash pretrain/download_glove.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 10:52:10,442 - root - INFO - Initializing word embedding with word2vec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('father', 0.5302285552024841)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import opennre\n",
    "model = opennre.get_model('wiki80_cnn_softmax')\n",
    "# manually download the pretrain model\n",
    "# https://thunlp.oss-cn-qingdao.aliyuncs.com/opennre/pretrain/nre/wiki80_cnn_softmax.pth.tar\n",
    "model.infer({'text': 'He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Aed Uaridnach (died 612).', 'h': {'pos': (18, 46)}, 't': {'pos': (78, 91)}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese_wwm\n",
    "\n",
    "## Load the pre-train LM\n",
    "1. download `Chinese_wmm` from [GitHub](https://github.com/ymcui/Chinese-BERT-wwm)\n",
    "2. extract the files and paste them to `opennre/pretrain/chinese_wwm`\n",
    "3. rename `bert_config.json` to `config.json`\n",
    "\n",
    "## Add new datasets in benchmark\n",
    "1. download dataset from [GitHub](https://github.com/taorui-plus/OpenNRE)\n",
    "2. add files into `./opennre/benchmark`\n",
    "\n",
    "## Train Chinese_wwm\n",
    "\n",
    "1. append `people-relation` to `train_supervised_..._.py` line 35\n",
    "2. line 66: `root_path = os.path.join(os.getcwd(), 'opennre')`\n",
    "3. comment `opennre.download(args.dataset, root_path=root_path)` line 77 in `train_supervised_..._.py`\n",
    "4. add `download_people_realtion` function in `pretrain.py`\n",
    "5. enter the command in Terminal\n",
    "    ```\n",
    "    python example/train_supervised_chinese_wwm.py \\\n",
    "        --pretrain_path {os.getcwd()}/opennre/pretrain/chinese_wwm \\\n",
    "        --dataset people-relation\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python example/train_supervised_chinese_wwm.py \\\n",
    "    --pretrain_path {os.getcwd()}/opennre/pretrain/chinese_wwm \\\n",
    "    --dataset people-relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import opennre\n",
    "model = opennre.get_model('chinese_wwm_entity')\n",
    "# model.cuda() # enable GPU\n",
    "\n",
    "# Load data\n",
    "import os, json\n",
    "\n",
    "cwd = os.getcwd()\n",
    "file_path = os.path.join(cwd, 'data.txt')\n",
    "\n",
    "with open(file_path, 'r', encoding = 'utf-8') as f:\n",
    "    new_data = f.readlines()\n",
    "\n",
    "# preprocess\n",
    "new_data = [i.strip().replace(\"'\", '\"') for i in new_data]\n",
    "new_data = [i.replace(\"(\", '[') for i in new_data]\n",
    "new_data = [i.replace(\")\", ']') for i in new_data]\n",
    "new_data = [json.loads(i) for i in new_data]\n",
    "\n",
    "def batch_infer(l: list):\n",
    "    \"\"\"\n",
    "    infer the list\n",
    "    \"\"\"\n",
    "\n",
    "    for i in l:\n",
    "        sen = i['text']\n",
    "        head = i['h']['pos']\n",
    "        head = sen[head[0] : head[1]]\n",
    "        tail = i['t']['pos']\n",
    "        tail = sen[tail[0] : tail[1]]\n",
    "        pred = model.infer(i)\n",
    "\n",
    "        print(f'The head is {head}\\nThe tail is {tail}\\nThe prediction is {pred}\\nThe sentence is\\n\\t {sen}\\n\\n')\n",
    "    \n",
    "    return \n",
    "\n",
    "batch_infer(new_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24ae7859e19c6c3f9566ca724d508fad34aee826cb5f07c22830f75813a565a1"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('opennre')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
